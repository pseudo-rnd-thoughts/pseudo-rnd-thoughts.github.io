---
layout: page
title: null
---

# Hi, I'm Mark

(Add photo)

I'm an RL Engineer at [Anyscale](https://www.anyscale.com/), working on [RLlib](https://docs.ray.io/en/latest/rllib/index.html) enabling the scaling of reinforcement learning agents from research to production.

In my free time, I led maintenance of [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) & [Gym](https://github.com/openai/gym), the standard APIs powering RL research worldwide, and a core team member at the [Farama Foundation](https://farama.org/).
Recently, I've branched out into Jax-first RL, working to build [Vamos](https://github.com/pseudo-rnd-thoughts/vamos) and [CleanJaxRL](to dolink), a next generation RL API and suite of easily readable RL training algorithms respectively. 

In 2025, I completed my [PhD](thesis) in Explainable RL at the University of Southampton, exploring how to explain agents' decision-making about their future intentions and still have an active interest in RL and AI research.

## Selected Projects

<div class="card-grid">
  <a class="card" href="https://github.com/Farama-Foundation/Gymnasium">
    <div class="card-title">Gymnasium</div>
    <p class="card-description">
      An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym).
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Lead Maintainer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/Farama-Foundation/Arcade-Learning-Environment">
    <div class="card-title">Arcade Learning Environment</div>
    <p class="card-description">
      A platform for AI research using Atari 2600 games as benchmarks for reinforcement learning algorithms.
    </p>
    <div class="card-meta">
      <span class="card-language cpp">C++</span>
      <span class="card-role">Maintainer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/pseudo-rnd-thoughts/Vamos">
    <div class="card-title">Vamos</div>
    <p class="card-description">
      An API for JAX-based Reinforcement Learning Environments.
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Developer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/pseudo-rnd-thoughts/CleanJaxRL">
    <div class="card-title">CleanJaxRL</div>
    <p class="card-description">
      A suite of RL training algorithms written purely in JAX to enable end-to-end JIT and vmapping.
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Developer</span>
    </div>
  </a>
</div>

## Selected Publications

For a complete list, see my [Google Scholar profile](https://scholar.google.com/citations?user=mBjei5sAAAAJ&hl=en).

<ul class="publications-list">
  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2407.17032">Gymnasium: A standard interface for reinforcement learning environments</a>
    <div class="publication-authors"><b>M Towers</b>, A Kwiatkowski, J Terry, et al.</div>
    <div class="publication-meta"><span class="publication-venue">arXiv preprint</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/18bf3d8e5bcf4a6d59e5c2c055cfd23e-Abstract-Datasets_and_Benchmarks.html">Minigrid & Miniworld: Modular & customizable reinforcement learning environments for goal-oriented tasks</a>
    <div class="publication-authors">M Chevalier-Boisvert, B Dai, <b>M Towers</b>, et al.</div>
    <div class="publication-meta"><span class="publication-venue">NeurIPS</span> · <span class="publication-year">2023</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2408.08230">Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators</a>
    <div class="publication-authors"><b>M Towers</b>, Y Du, C Freeman, TJ Norman</div>
    <div class="publication-meta"><span class="publication-venue">ECAI</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/pdf/2510.16956">A Comparative User Evaluation of XRL Explanations using Goal Identification</a>
    <div class="publication-authors"><b>M Towers</b>, Y Du, C Freeman, TJ Norman</div>
    <div class="publication-meta"><span class="publication-venue">ECAI EXCD</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2411.03820">Beyond the Rainbow: High performance deep reinforcement learning on a desktop PC</a>
    <div class="publication-authors">T Clark, <b>M Towers</b>, C Evers, J Hare</div>
    <div class="publication-meta"><span class="publication-venue">ICML</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2501.19256">Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning</a>
    <div class="publication-authors">B Gyevnar, <b>M Towers</b></div>
    <div class="publication-meta"><span class="publication-venue">arXiv preprint</span> · <span class="publication-year">2025</span></div>
  </li>
</ul>
