---
layout: page
title: null
---

<div class="bio-section">
  <div class="bio-photo">
    <img src="{{ '/assets/images/IMG_2629.jpeg' | relative_url }}" alt="Mark Towers">
  </div>
  <div class="bio-content">
    <h1>Hi, I'm Mark</h1>
    <p class="bio-tagline">Reinforcement learning researcher with a PhD in Explainable RL</p>
    <p>Currently, I'm a Software Engineer at <a href="https://www.anyscale.com/">Anyscale</a>, working on <a href="https://docs.ray.io/en/latest/rllib/index.html">RLlib</a> helping to scale reinforcement learning agents for real-world problems.</p>
    <p>In my free time, I lead maintenance of <a href="https://github.com/Farama-Foundation/Gymnasium">Gymnasium</a> & <a href="https://github.com/openai/gym">Gym</a>, the standard APIs powering RL research worldwide, and am a core team member at the <a href="https://farama.org/">Farama Foundation</a>.</p>
    <p>In 2025, I completed a <a href="https://eprints.soton.ac.uk/502074/1/archival_phd_thesis.pdf">PhD</a> in Explainable RL at the University of Southampton, resulting in numerous published papers on explaining agents' decision-making. A selection of my publications is listed below.</p>
  </div>
</div>

## Selected Projects

<div class="card-grid">
  <a class="card" href="https://github.com/Farama-Foundation/Gymnasium">
    <div class="card-title">Gymnasium</div>
    <p class="card-description">
      An API standard for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym).
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Lead Maintainer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/Farama-Foundation/Arcade-Learning-Environment">
    <div class="card-title">Arcade Learning Environment</div>
    <p class="card-description">
      A platform for AI research using Atari 2600 games as benchmarks for reinforcement learning algorithms.
    </p>
    <div class="card-meta">
      <span class="card-language cpp">C++</span>
      <span class="card-role">Maintainer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/pseudo-rnd-thoughts/Vamos">
    <div class="card-title">Vamos</div>
    <p class="card-description">
      An API for JAX-based Reinforcement Learning Environments.
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Developer</span>
    </div>
  </a>

  <a class="card" href="https://github.com/pseudo-rnd-thoughts/CleanJaxRL">
    <div class="card-title">CleanJaxRL</div>
    <p class="card-description">
      A suite of RL training algorithms written purely in JAX to enable end-to-end JIT and vmapping.
    </p>
    <div class="card-meta">
      <span class="card-language python">Python</span>
      <span class="card-role">Developer</span>
    </div>
  </a>
</div>

## Selected Publications

For a complete list, see my [Google Scholar profile](https://scholar.google.com/citations?user=mBjei5sAAAAJ&hl=en).

<ul class="publications-list">
  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2407.17032">Gymnasium: A standard interface for reinforcement learning environments</a>
    <div class="publication-authors"><b>M Towers</b>, A Kwiatkowski, J Terry, et al.</div>
    <div class="publication-meta"><span class="publication-venue">arXiv preprint</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/18bf3d8e5bcf4a6d59e5c2c055cfd23e-Abstract-Datasets_and_Benchmarks.html">Minigrid & Miniworld: Modular & customizable reinforcement learning environments for goal-oriented tasks</a>
    <div class="publication-authors">M Chevalier-Boisvert, B Dai, <b>M Towers</b>, et al.</div>
    <div class="publication-meta"><span class="publication-venue">NeurIPS</span> · <span class="publication-year">2023</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2408.08230">Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators</a>
    <div class="publication-authors"><b>M Towers</b>, Y Du, C Freeman, TJ Norman</div>
    <div class="publication-meta"><span class="publication-venue">ECAI</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/pdf/2510.16956">A Comparative User Evaluation of XRL Explanations using Goal Identification</a>
    <div class="publication-authors"><b>M Towers</b>, Y Du, C Freeman, TJ Norman</div>
    <div class="publication-meta"><span class="publication-venue">ECAI EXCD</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2411.03820">Beyond the Rainbow: High performance deep reinforcement learning on a desktop PC</a>
    <div class="publication-authors">T Clark, <b>M Towers</b>, C Evers, J Hare</div>
    <div class="publication-meta"><span class="publication-venue">ICML</span> · <span class="publication-year">2024</span></div>
  </li>

  <li class="publication-item">
    <a class="publication-title" href="https://arxiv.org/abs/2501.19256">Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning</a>
    <div class="publication-authors">B Gyevnar, <b>M Towers</b></div>
    <div class="publication-meta"><span class="publication-venue">arXiv preprint</span> · <span class="publication-year">2025</span></div>
  </li>
</ul>
